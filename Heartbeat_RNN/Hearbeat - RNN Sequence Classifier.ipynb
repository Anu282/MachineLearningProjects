{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heartbeat - RNN Sequence Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 187 data points (columns) for each measurement. This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "We will use the **hearbeat.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T187 are the values of a measurement on the timeline (there are 187 data points, or columns, in a single measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T187**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important note:\n",
    "\n",
    "Looks like the original length of the sequences were not the same in the data set. For example, one sequence (i.e., row) had 187 columns, while another one had 150 only. Therefore, the creators of the data set did a \"zero padding\". This means that they added zeros at end of each sequence to make them the same length. This way, all sequences (i.e., rows) were made to have 187 columns.\n",
    "\n",
    "If we don't account for the zero-padding, we will create biased models. To account for this, we can use the following as your first layer of your models:<br>\n",
    "`tf.keras.layers.Masking(mask_value=0, input_shape=[n_steps, n_inputs])`<br>\n",
    "(Of course, you need to enter your own values for n_steps and n_inputs). After we add this layer, we continue with other layers as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert as many cells as you need for data prep\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"heartbeat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9026, 188)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T179</th>\n",
       "      <th>T180</th>\n",
       "      <th>T181</th>\n",
       "      <th>T182</th>\n",
       "      <th>T183</th>\n",
       "      <th>T184</th>\n",
       "      <th>T185</th>\n",
       "      <th>T186</th>\n",
       "      <th>T187</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.3940</td>\n",
       "      <td>0.3580</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.3620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.626  0.276  0.3250  0.4310  0.3900  0.3940  0.3580  0.3740   \n",
       "\n",
       "      T10  ...  T179  T180  T181  T182  T183  T184  T185  T186  T187  Target  \n",
       "0  0.1380  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "1  0.0781  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "2  0.0857  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "3  0.0155  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "4  0.3620  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Target']\n",
    "x = data.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 3, 0, 0, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the first 10 values of the train_y data set\n",
    "train_y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.973 , 0.927 , 0.367 , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.988 , 1.    , 0.954 , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.945 , 0.595 , 0.0199, ..., 0.    , 0.    , 0.    ],\n",
       "       ...,\n",
       "       [0.88  , 0.967 , 0.908 , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.    , 0.0207, 0.022 , ..., 0.    , 0.    , 0.    ],\n",
       "       [0.993 , 1.    , 0.778 , ..., 0.    , 0.    , 0.    ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keras expects a different input format:\n",
    "#Data needs to have 3 dimensions\n",
    "\n",
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6318, 187, 1), (6318,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.973 ],\n",
       "        [0.927 ],\n",
       "        [0.367 ],\n",
       "        ...,\n",
       "        [0.    ],\n",
       "        [0.    ],\n",
       "        [0.    ]],\n",
       "\n",
       "       [[0.988 ],\n",
       "        [1.    ],\n",
       "        [0.954 ],\n",
       "        ...,\n",
       "        [0.    ],\n",
       "        [0.    ],\n",
       "        [0.    ]],\n",
       "\n",
       "       [[0.945 ],\n",
       "        [0.595 ],\n",
       "        [0.0199],\n",
       "        ...,\n",
       "        [0.    ],\n",
       "        [0.    ],\n",
       "        [0.    ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.88  ],\n",
       "        [0.967 ],\n",
       "        [0.908 ],\n",
       "        ...,\n",
       "        [0.    ],\n",
       "        [0.    ],\n",
       "        [0.    ]],\n",
       "\n",
       "       [[0.    ],\n",
       "        [0.0207],\n",
       "        [0.022 ],\n",
       "        ...,\n",
       "        [0.    ],\n",
       "        [0.    ],\n",
       "        [0.    ]],\n",
       "\n",
       "       [[0.993 ],\n",
       "        [1.    ],\n",
       "        [0.778 ],\n",
       "        ...,\n",
       "        [0.    ],\n",
       "        [0.    ],\n",
       "        [0.    ]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.581875\n",
       "4.0    0.178152\n",
       "2.0    0.160425\n",
       "1.0    0.061600\n",
       "3.0    0.017948\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model:Model 1\n",
    "\n",
    "### Make sure to add the masking layer to the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 36\n",
    "n_inputs = 1\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=0, input_shape=[n_steps, n_inputs]),\n",
    "    tf.keras.layers.LSTM(10, input_shape=[n_steps, n_inputs]),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_6_input'), name='masking_6_input', description=\"created by layer 'masking_6_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_6_input'), name='masking_6_input', description=\"created by layer 'masking_6_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "198/198 [==============================] - ETA: 0s - loss: 1.2795 - accuracy: 0.5546WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_6_input'), name='masking_6_input', description=\"created by layer 'masking_6_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "198/198 [==============================] - 23s 88ms/step - loss: 1.2795 - accuracy: 0.5546 - val_loss: 1.1406 - val_accuracy: 0.5794\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 18s 90ms/step - loss: 1.1093 - accuracy: 0.5829 - val_loss: 1.1003 - val_accuracy: 0.5794\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 22s 109ms/step - loss: 1.0902 - accuracy: 0.5829 - val_loss: 1.0981 - val_accuracy: 0.5794\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 22s 109ms/step - loss: 1.1260 - accuracy: 0.5828 - val_loss: 1.1533 - val_accuracy: 0.5794\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 24s 121ms/step - loss: 1.1034 - accuracy: 0.5981 - val_loss: 1.0963 - val_accuracy: 0.6067\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 27s 134ms/step - loss: 1.1161 - accuracy: 0.5801 - val_loss: 1.1115 - val_accuracy: 0.5816\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 24s 120ms/step - loss: 1.0914 - accuracy: 0.5776 - val_loss: 1.0724 - val_accuracy: 0.5838\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 20s 102ms/step - loss: 1.0598 - accuracy: 0.6053 - val_loss: 1.0638 - val_accuracy: 0.6100\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 25s 124ms/step - loss: 1.0383 - accuracy: 0.6113 - val_loss: 1.0296 - val_accuracy: 0.6126\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 21s 106ms/step - loss: 1.0674 - accuracy: 0.5867 - val_loss: 1.0541 - val_accuracy: 0.6001\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 22s 111ms/step - loss: 1.0198 - accuracy: 0.6155 - val_loss: 1.0083 - val_accuracy: 0.6422\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 24s 120ms/step - loss: 0.9772 - accuracy: 0.6630 - val_loss: 0.9902 - val_accuracy: 0.6739\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 26s 129ms/step - loss: 0.9477 - accuracy: 0.6858 - val_loss: 1.0020 - val_accuracy: 0.6710\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 21s 105ms/step - loss: 0.9231 - accuracy: 0.6975 - val_loss: 0.9292 - val_accuracy: 0.6953\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 19s 97ms/step - loss: 0.8980 - accuracy: 0.7032 - val_loss: 0.9152 - val_accuracy: 0.6869\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 22s 110ms/step - loss: 0.8793 - accuracy: 0.7081 - val_loss: 0.8890 - val_accuracy: 0.7123\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 21s 106ms/step - loss: 0.8646 - accuracy: 0.7085 - val_loss: 0.8831 - val_accuracy: 0.6994\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 21s 104ms/step - loss: 0.8492 - accuracy: 0.7175 - val_loss: 0.8667 - val_accuracy: 0.7064\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 23s 118ms/step - loss: 0.8367 - accuracy: 0.7236 - val_loss: 0.8460 - val_accuracy: 0.7326\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 24s 123ms/step - loss: 0.8223 - accuracy: 0.7268 - val_loss: 0.8464 - val_accuracy: 0.7201\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 23s 114ms/step - loss: 0.8147 - accuracy: 0.7347 - val_loss: 0.8372 - val_accuracy: 0.7242\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 23s 114ms/step - loss: 0.8049 - accuracy: 0.7366 - val_loss: 0.8410 - val_accuracy: 0.7315\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 21s 105ms/step - loss: 0.7876 - accuracy: 0.7479 - val_loss: 0.8032 - val_accuracy: 0.7422\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 22s 112ms/step - loss: 0.7774 - accuracy: 0.7483 - val_loss: 0.7938 - val_accuracy: 0.7426\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 23s 117ms/step - loss: 0.7640 - accuracy: 0.7558 - val_loss: 0.7806 - val_accuracy: 0.7430\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 26s 132ms/step - loss: 0.7562 - accuracy: 0.7559 - val_loss: 0.7749 - val_accuracy: 0.7596\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 20s 103ms/step - loss: 0.7443 - accuracy: 0.7604 - val_loss: 0.7671 - val_accuracy: 0.7611\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 21s 105ms/step - loss: 0.7378 - accuracy: 0.7638 - val_loss: 0.7552 - val_accuracy: 0.7703\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 20s 100ms/step - loss: 0.7298 - accuracy: 0.7743 - val_loss: 0.7486 - val_accuracy: 0.7618\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 20s 103ms/step - loss: 0.7292 - accuracy: 0.7695 - val_loss: 0.7409 - val_accuracy: 0.7596\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 27s 138ms/step - loss: 0.7147 - accuracy: 0.7722 - val_loss: 0.7248 - val_accuracy: 0.7640\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 24s 123ms/step - loss: 0.7060 - accuracy: 0.7786 - val_loss: 0.7377 - val_accuracy: 0.7674\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 20s 102ms/step - loss: 0.6980 - accuracy: 0.7816 - val_loss: 0.7289 - val_accuracy: 0.7692\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 19s 96ms/step - loss: 0.6822 - accuracy: 0.7870 - val_loss: 0.7125 - val_accuracy: 0.7803\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 27s 135ms/step - loss: 0.6753 - accuracy: 0.7931 - val_loss: 0.6965 - val_accuracy: 0.7781\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 28s 142ms/step - loss: 0.6761 - accuracy: 0.7936 - val_loss: 0.6834 - val_accuracy: 0.7821\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 21s 106ms/step - loss: 0.6729 - accuracy: 0.7939 - val_loss: 0.6792 - val_accuracy: 0.7851\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 25s 125ms/step - loss: 0.6623 - accuracy: 0.7938 - val_loss: 0.6683 - val_accuracy: 0.7932\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 30s 150ms/step - loss: 0.6540 - accuracy: 0.7982 - val_loss: 0.6746 - val_accuracy: 0.7910\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 26s 130ms/step - loss: 0.6444 - accuracy: 0.8047 - val_loss: 0.6644 - val_accuracy: 0.7932\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 19s 96ms/step - loss: 0.6405 - accuracy: 0.8033 - val_loss: 0.6541 - val_accuracy: 0.7932\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 23s 118ms/step - loss: 0.6355 - accuracy: 0.8037 - val_loss: 0.6793 - val_accuracy: 0.7818\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 23s 114ms/step - loss: 0.6258 - accuracy: 0.8085 - val_loss: 0.6438 - val_accuracy: 0.7995\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 23s 115ms/step - loss: 0.6244 - accuracy: 0.8086 - val_loss: 0.6570 - val_accuracy: 0.7906\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 26s 132ms/step - loss: 0.6202 - accuracy: 0.8096 - val_loss: 0.6421 - val_accuracy: 0.7969\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 23s 117ms/step - loss: 0.6160 - accuracy: 0.8102 - val_loss: 0.6644 - val_accuracy: 0.7921\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 21s 104ms/step - loss: 0.6090 - accuracy: 0.8135 - val_loss: 0.6330 - val_accuracy: 0.8024\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 24s 121ms/step - loss: 0.7087 - accuracy: 0.7768 - val_loss: 0.6436 - val_accuracy: 0.7954\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 20s 100ms/step - loss: 0.6145 - accuracy: 0.8074 - val_loss: 0.6347 - val_accuracy: 0.7958\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 22s 109ms/step - loss: 0.5970 - accuracy: 0.8132 - val_loss: 1.4782 - val_accuracy: 0.4967\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y)\n",
    "                    ,callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.478166937828064, 0.496676504611969]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.48\n",
      "accuracy: 49.67%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM One Layer: Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 36\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Masking(mask_value=0, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(5, activation='softmax' , input_shape=[n_steps, n_inputs])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "198/198 [==============================] - ETA: 0s - loss: 1.4535 - accuracy: 0.5825WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_5_input'), name='masking_5_input', description=\"created by layer 'masking_5_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "198/198 [==============================] - 18s 79ms/step - loss: 1.4535 - accuracy: 0.5825 - val_loss: 1.3341 - val_accuracy: 0.5794\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 18s 91ms/step - loss: 1.2725 - accuracy: 0.5829 - val_loss: 1.2366 - val_accuracy: 0.5794\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 21s 104ms/step - loss: 1.2128 - accuracy: 0.5829 - val_loss: 1.1966 - val_accuracy: 0.5794\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 20s 102ms/step - loss: 1.1782 - accuracy: 0.5829 - val_loss: 1.1670 - val_accuracy: 0.5794\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 21s 107ms/step - loss: 1.1517 - accuracy: 0.5828 - val_loss: 1.1426 - val_accuracy: 0.5772\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 22s 109ms/step - loss: 1.1307 - accuracy: 0.5744 - val_loss: 1.1227 - val_accuracy: 0.5783\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 21s 104ms/step - loss: 1.1155 - accuracy: 0.5788 - val_loss: 1.1106 - val_accuracy: 0.5827\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 20s 102ms/step - loss: 1.1048 - accuracy: 0.5840 - val_loss: 1.1015 - val_accuracy: 0.5897\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 21s 109ms/step - loss: 1.0950 - accuracy: 0.5901 - val_loss: 1.0937 - val_accuracy: 0.5916\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 21s 104ms/step - loss: 1.0867 - accuracy: 0.5915 - val_loss: 1.0897 - val_accuracy: 0.5919\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 21s 107ms/step - loss: 1.0809 - accuracy: 0.5902 - val_loss: 1.0850 - val_accuracy: 0.5857\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 24s 122ms/step - loss: 1.0770 - accuracy: 0.5909 - val_loss: 1.0816 - val_accuracy: 0.5857\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 27s 136ms/step - loss: 1.0741 - accuracy: 0.5907 - val_loss: 1.0803 - val_accuracy: 0.5842\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 26s 133ms/step - loss: 1.0720 - accuracy: 0.5901 - val_loss: 1.0793 - val_accuracy: 0.5894\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 20s 100ms/step - loss: 1.0701 - accuracy: 0.5904 - val_loss: 1.0766 - val_accuracy: 0.5886\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 19s 97ms/step - loss: 1.0680 - accuracy: 0.5915 - val_loss: 1.0753 - val_accuracy: 0.5897\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 21s 104ms/step - loss: 1.0665 - accuracy: 0.5916 - val_loss: 1.0736 - val_accuracy: 0.5901\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 19s 96ms/step - loss: 1.0654 - accuracy: 0.5926 - val_loss: 1.0720 - val_accuracy: 0.5901\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 26s 133ms/step - loss: 1.0636 - accuracy: 0.5924 - val_loss: 1.0721 - val_accuracy: 0.5919\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 24s 122ms/step - loss: 1.0628 - accuracy: 0.5923 - val_loss: 1.0698 - val_accuracy: 0.5912\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 27s 136ms/step - loss: 1.0612 - accuracy: 0.5920 - val_loss: 1.0689 - val_accuracy: 0.5919\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 23s 114ms/step - loss: 1.0602 - accuracy: 0.5926 - val_loss: 1.0675 - val_accuracy: 0.5931\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 24s 121ms/step - loss: 1.0588 - accuracy: 0.5918 - val_loss: 1.0664 - val_accuracy: 0.5931\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 23s 114ms/step - loss: 1.0572 - accuracy: 0.5929 - val_loss: 1.0659 - val_accuracy: 0.5931\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 20s 99ms/step - loss: 1.0562 - accuracy: 0.5923 - val_loss: 1.0643 - val_accuracy: 0.5934\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 22s 110ms/step - loss: 1.0553 - accuracy: 0.5921 - val_loss: 1.0656 - val_accuracy: 0.5934\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 27s 137ms/step - loss: 1.0549 - accuracy: 0.5934 - val_loss: 1.0634 - val_accuracy: 0.5934\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 20s 101ms/step - loss: 1.0528 - accuracy: 0.5928 - val_loss: 1.0609 - val_accuracy: 0.5934\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 22s 110ms/step - loss: 1.0516 - accuracy: 0.5939 - val_loss: 1.0593 - val_accuracy: 0.5945\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 22s 109ms/step - loss: 1.0507 - accuracy: 0.5937 - val_loss: 1.0582 - val_accuracy: 0.5938\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 24s 121ms/step - loss: 1.0491 - accuracy: 0.5945 - val_loss: 1.0591 - val_accuracy: 0.5956\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 23s 114ms/step - loss: 1.0479 - accuracy: 0.5951 - val_loss: 1.0580 - val_accuracy: 0.5953\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 22s 109ms/step - loss: 1.0471 - accuracy: 0.5945 - val_loss: 1.0550 - val_accuracy: 0.5956\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 29s 147ms/step - loss: 1.0458 - accuracy: 0.5958 - val_loss: 1.0538 - val_accuracy: 0.5975\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 23s 115ms/step - loss: 1.0441 - accuracy: 0.5947 - val_loss: 1.0529 - val_accuracy: 0.5964\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 26s 132ms/step - loss: 1.0431 - accuracy: 0.5954 - val_loss: 1.0509 - val_accuracy: 0.5968\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 20s 102ms/step - loss: 1.0416 - accuracy: 0.5969 - val_loss: 1.0514 - val_accuracy: 0.5953\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 20s 100ms/step - loss: 1.0402 - accuracy: 0.5967 - val_loss: 1.0482 - val_accuracy: 0.5982\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 23s 115ms/step - loss: 1.0387 - accuracy: 0.5969 - val_loss: 1.0477 - val_accuracy: 0.5964\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 23s 114ms/step - loss: 1.0380 - accuracy: 0.5975 - val_loss: 1.0458 - val_accuracy: 0.5964\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 28s 142ms/step - loss: 1.0359 - accuracy: 0.5972 - val_loss: 1.0438 - val_accuracy: 0.5993\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 21s 108ms/step - loss: 1.0343 - accuracy: 0.5973 - val_loss: 1.0438 - val_accuracy: 0.5997\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 25s 128ms/step - loss: 1.0329 - accuracy: 0.5980 - val_loss: 1.0414 - val_accuracy: 0.5986\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 25s 127ms/step - loss: 1.0307 - accuracy: 0.5980 - val_loss: 1.0391 - val_accuracy: 0.5990\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 35s 178ms/step - loss: 1.0294 - accuracy: 0.5988 - val_loss: 1.0378 - val_accuracy: 0.6008\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 36s 184ms/step - loss: 1.0268 - accuracy: 0.5994 - val_loss: 1.0349 - val_accuracy: 0.5993\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 45s 227ms/step - loss: 1.0246 - accuracy: 0.5984 - val_loss: 1.0330 - val_accuracy: 0.5993\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 33s 168ms/step - loss: 1.0222 - accuracy: 0.5989 - val_loss: 1.0303 - val_accuracy: 0.6004\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 21s 106ms/step - loss: 1.0193 - accuracy: 0.6008 - val_loss: 1.0270 - val_accuracy: 0.6016\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 23s 115ms/step - loss: 1.0167 - accuracy: 0.6019 - val_loss: 1.0245 - val_accuracy: 0.6112\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.024549126625061, 0.6111521124839783]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.02\n",
      "accuracy: 61.12%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.02\n",
      "accuracy: 61.12%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model\n",
    "\n",
    "### Make sure to add the masking layer to this model too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 36\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Masking(mask_value=0, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(20, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(20, return_sequences=True),\n",
    "    keras.layers.GRU(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_7_input'), name='masking_7_input', description=\"created by layer 'masking_7_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_7_input'), name='masking_7_input', description=\"created by layer 'masking_7_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "198/198 [==============================] - ETA: 0s - loss: 1.1783 - accuracy: 0.5703WARNING:tensorflow:Model was constructed with shape (None, 36, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 36, 1), dtype=tf.float32, name='masking_7_input'), name='masking_7_input', description=\"created by layer 'masking_7_input'\"), but it was called on an input with incompatible shape (None, 187, 1).\n",
      "198/198 [==============================] - 96s 411ms/step - loss: 1.1783 - accuracy: 0.5703 - val_loss: 1.0789 - val_accuracy: 0.5569\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 95s 479ms/step - loss: 1.0200 - accuracy: 0.6102 - val_loss: 0.9775 - val_accuracy: 0.6403\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 87s 441ms/step - loss: 0.8359 - accuracy: 0.7229 - val_loss: 0.7664 - val_accuracy: 0.7397\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 91s 460ms/step - loss: 0.6841 - accuracy: 0.7863 - val_loss: 0.6954 - val_accuracy: 0.7862\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 111s 561ms/step - loss: 0.6420 - accuracy: 0.8052 - val_loss: 0.6900 - val_accuracy: 0.7836\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 85s 431ms/step - loss: 0.6094 - accuracy: 0.8151 - val_loss: 0.6492 - val_accuracy: 0.8058\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 100s 506ms/step - loss: 0.5766 - accuracy: 0.8262 - val_loss: 0.6146 - val_accuracy: 0.8091\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 131s 664ms/step - loss: 0.5438 - accuracy: 0.8303 - val_loss: 0.5759 - val_accuracy: 0.8227\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 144s 730ms/step - loss: 0.5135 - accuracy: 0.8374 - val_loss: 0.5902 - val_accuracy: 0.8213\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 97s 491ms/step - loss: 0.4893 - accuracy: 0.8469 - val_loss: 0.5438 - val_accuracy: 0.8316\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 98s 495ms/step - loss: 0.4718 - accuracy: 0.8509 - val_loss: 0.5594 - val_accuracy: 0.8257\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 98s 498ms/step - loss: 0.4558 - accuracy: 0.8585 - val_loss: 0.5218 - val_accuracy: 0.8394\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 88s 445ms/step - loss: 0.4387 - accuracy: 0.8609 - val_loss: 0.4909 - val_accuracy: 0.8434\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 86s 432ms/step - loss: 0.4287 - accuracy: 0.8640 - val_loss: 0.4714 - val_accuracy: 0.8523\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 79s 398ms/step - loss: 0.4151 - accuracy: 0.8697 - val_loss: 0.4847 - val_accuracy: 0.8490\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 87s 437ms/step - loss: 0.4035 - accuracy: 0.8742 - val_loss: 0.4573 - val_accuracy: 0.8567\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 77s 389ms/step - loss: 0.3982 - accuracy: 0.8777 - val_loss: 0.4512 - val_accuracy: 0.8637\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 91s 458ms/step - loss: 0.3843 - accuracy: 0.8792 - val_loss: 0.4405 - val_accuracy: 0.8652\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 93s 469ms/step - loss: 0.3729 - accuracy: 0.8851 - val_loss: 0.4348 - val_accuracy: 0.8674\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 81s 409ms/step - loss: 0.3711 - accuracy: 0.8837 - val_loss: 0.4259 - val_accuracy: 0.8689\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 77s 391ms/step - loss: 0.3613 - accuracy: 0.8876 - val_loss: 0.4319 - val_accuracy: 0.8582\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 76s 383ms/step - loss: 0.3540 - accuracy: 0.8902 - val_loss: 0.3932 - val_accuracy: 0.8804\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 81s 411ms/step - loss: 0.3461 - accuracy: 0.8911 - val_loss: 0.3922 - val_accuracy: 0.8741\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 81s 410ms/step - loss: 0.3413 - accuracy: 0.8955 - val_loss: 0.3916 - val_accuracy: 0.8733\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 96s 486ms/step - loss: 0.3325 - accuracy: 0.8997 - val_loss: 0.4433 - val_accuracy: 0.8567\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 88s 447ms/step - loss: 0.3259 - accuracy: 0.8982 - val_loss: 0.3901 - val_accuracy: 0.8770\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 84s 423ms/step - loss: 0.3235 - accuracy: 0.9017 - val_loss: 0.3953 - val_accuracy: 0.8792\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 84s 427ms/step - loss: 0.3187 - accuracy: 0.9020 - val_loss: 0.3732 - val_accuracy: 0.8874\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 80s 406ms/step - loss: 0.3132 - accuracy: 0.9022 - val_loss: 0.3586 - val_accuracy: 0.8877\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 80s 406ms/step - loss: 0.3083 - accuracy: 0.9036 - val_loss: 0.3582 - val_accuracy: 0.8866\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 82s 415ms/step - loss: 0.2993 - accuracy: 0.9044 - val_loss: 0.3630 - val_accuracy: 0.8859\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 75s 377ms/step - loss: 0.2996 - accuracy: 0.9084 - val_loss: 0.3608 - val_accuracy: 0.8829\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 81s 409ms/step - loss: 0.2886 - accuracy: 0.9125 - val_loss: 0.3708 - val_accuracy: 0.8844\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 73s 370ms/step - loss: 0.2874 - accuracy: 0.9087 - val_loss: 0.3402 - val_accuracy: 0.8933\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 75s 376ms/step - loss: 0.2851 - accuracy: 0.9072 - val_loss: 0.3565 - val_accuracy: 0.8885\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 77s 390ms/step - loss: 0.2792 - accuracy: 0.9112 - val_loss: 0.3258 - val_accuracy: 0.9025\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 77s 390ms/step - loss: 0.2753 - accuracy: 0.9142 - val_loss: 0.3526 - val_accuracy: 0.8900\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 109s 552ms/step - loss: 0.2677 - accuracy: 0.9160 - val_loss: 0.3451 - val_accuracy: 0.8970\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 114s 575ms/step - loss: 0.2634 - accuracy: 0.9174 - val_loss: 0.3415 - val_accuracy: 0.8911\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 84s 426ms/step - loss: 0.2655 - accuracy: 0.9172 - val_loss: 0.3468 - val_accuracy: 0.8907\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 90s 454ms/step - loss: 0.2550 - accuracy: 0.9177 - val_loss: 0.3604 - val_accuracy: 0.8892\n",
      "Epoch 00041: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=50,\n",
    "                   validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3604240119457245, 0.8892171382904053]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.36\n",
      "accuracy: 88.92%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.581875\n",
       "4.0    0.178152\n",
       "2.0    0.160425\n",
       "1.0    0.061600\n",
       "3.0    0.017948\n",
       "Name: Target, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].value_counts()/len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Briefly answer the following questions: (2 points) \n",
    "1) Which model performs the best (and why)?<br>\n",
    "2) What is the baseline value?<br>\n",
    "3) Does the best model perform better than the baseline (and why)?<br>\n",
    "4) Does the best model exhibit any overfitting; what did you do about it?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) GRU Model performs the best with accuracy of 88.9%(89%) over other models LSTM Model 1(accuracy is 49%)and LSTM one layer (accuracy is 61%)\n",
    "2) Baseline value is 58.18%\n",
    "3) GRU model performs better than baseline since its accuracy is 88.37% over baseline accuracy of 58.18%\n",
    "4) The model does not exhibit overfitting since the training accuracy is 92% and test accuracy is 89% and the accuracies are close to one another.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
