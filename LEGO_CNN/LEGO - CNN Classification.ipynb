{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO - CNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains rendered images of 16 different types of Lego bricks. This is an image classification task: build a model that can correctly identify lego bricks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the **train** folder and build a model to predict the **category** of each image. Then, validate your model on the images in the **valid** folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6379 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image Data Generator manipulates and \"augments\" images\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "# Directory Iterator reads images from a directory\n",
    "\n",
    "train_data = DirectoryIterator(\n",
    "    directory=\"LEGO/train\",\n",
    "    image_data_generator = train_datagen,\n",
    "    target_size=(16, 16),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1555 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "valid_data = DirectoryIterator(\n",
    "    directory=\"LEGO/valid\",\n",
    "    image_data_generator = valid_datagen,\n",
    "    target_size=(16, 16),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 133,712\n",
      "Trainable params: 133,712\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(16,16,3)))\n",
    "\n",
    "#model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "\n",
    "#model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "####\n",
    "##model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "##model.add(MaxPooling2D(pool_size=(2, 2))) in presence of this layer accuracy is 58%\n",
    "#model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# initiate adam optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 [==============================] - ETA: 0s - loss: 1.7014 - accuracy: 0.3944WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "100/100 [==============================] - 23s 225ms/step - loss: 1.7014 - accuracy: 0.3944 - val_loss: 0.9529 - val_accuracy: 0.6193\n",
      "Epoch 2/5\n",
      "100/100 [==============================] - 7s 67ms/step - loss: 1.1323 - accuracy: 0.5624\n",
      "Epoch 3/5\n",
      "100/100 [==============================] - 6s 55ms/step - loss: 1.0099 - accuracy: 0.6266\n",
      "Epoch 4/5\n",
      "100/100 [==============================] - 5s 47ms/step - loss: 0.9383 - accuracy: 0.6489\n",
      "Epoch 5/5\n",
      "100/100 [==============================] - 4s 41ms/step - loss: 0.8751 - accuracy: 0.6618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x221c0748550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_data,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=5,\n",
    "        validation_data=valid_data,\n",
    "        validation_steps=50\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
