{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alcohol Consumption in minors - Ensemble Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains data about high school students. Each row represents a single student. The columns include the characteristics of deidentified students. This is a binary classification task: predict whether a student drinks alcohol or not (this is the **Alc** column: 1=Yes, 0=No). This is an important prediction task to detect underage drinking and deploy intervention techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description of variables are provided in \"Alcohol - Data Dictionary.docx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the **alcohol.csv** data set and build a model to predict **Alc**. Build (at least) the models required below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data\n",
    "## feature engineering: create one new variable from existing ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime</th>\n",
       "      <th>studytime</th>\n",
       "      <th>failures</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>gender</th>\n",
       "      <th>alc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  Medu  Fedu  traveltime  studytime  failures  famrel  freetime  goout  \\\n",
       "0   18     2     1           4          2         0       5         4      2   \n",
       "1   18     4     3           1          0         0       4         4      2   \n",
       "2   15     4     3           2          3         0       5         3      4   \n",
       "3   15     3     3           1          4         0       4         3      3   \n",
       "4   17     3     2           1          2         0       5         3      5   \n",
       "\n",
       "   health  absences gender  alc  \n",
       "0       5         2      M    1  \n",
       "1       3         9      M    1  \n",
       "2       5         0      F    0  \n",
       "3       3        10      F    0  \n",
       "4       5         2      M    1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will predict the \"price_gte_150\" value in the data set:\n",
    "\n",
    "alcohol = pd.read_csv(\"alcohol.csv\")\n",
    "alcohol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(alcohol, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "Medu          0\n",
       "Fedu          0\n",
       "traveltime    0\n",
       "studytime     0\n",
       "failures      0\n",
       "famrel        0\n",
       "freetime      0\n",
       "goout         0\n",
       "health        0\n",
       "absences      0\n",
       "gender        0\n",
       "alc           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age           0\n",
       "Medu          0\n",
       "Fedu          0\n",
       "traveltime    0\n",
       "studytime     0\n",
       "failures      0\n",
       "famrel        0\n",
       "freetime      0\n",
       "goout         0\n",
       "health        0\n",
       "absences      0\n",
       "gender        0\n",
       "alc           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = train_set.drop(['alc'], axis=1)\n",
    "#test = test_set.drop(['alc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_set['alc']\n",
    "test_y = test_set['alc']\n",
    "\n",
    "train_inputs = train_set.drop(['alc'], axis=1)\n",
    "test_inputs = test_set.drop(['alc'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: Let's derive a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_col(df):\n",
    "    #Create a copy so that we don't overwrite the existing dataframe\n",
    "    df1 = df.copy()\n",
    "    \n",
    "    #df1['num_failures_binned'] = pd.cut(df1['number_of_reviews'],\n",
    "     #                                  bins=[0,0.5,1,5,15,50,10000],  #bins=[exclusive, inclusive]\n",
    "      #                                 labels=False, \n",
    "       #                                include_lowest=True,\n",
    "        #                               ordered=True)\n",
    "        \n",
    "    df1['IsAdult'] = np.where(df1['age']>=18,1,0)\n",
    "    \n",
    "#     You can also do this if you want categorical values:    \n",
    "#     df1['num_reviews_binned'] = pd.cut(df1['number_of_reviews'],\n",
    "#                                        bins=[0,0.5,1,5,15,50,10000], \n",
    "#                                        labels=['None','Very few','Few','Medium','Many','Too many'], \n",
    "#                                        include_lowest=True,\n",
    "#                                        ordered=False)\n",
    "\n",
    "    \n",
    "    return df1[['IsAdult']]\n",
    "    # You can use this to check whether the calculation is made correctly:\n",
    "    #return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsAdult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12759</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4374</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8561</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10697</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19424</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23800 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       IsAdult\n",
       "12759        0\n",
       "4374         0\n",
       "8561         0\n",
       "10697        0\n",
       "19424        0\n",
       "...        ...\n",
       "16850        0\n",
       "6265         0\n",
       "11284        0\n",
       "860          1\n",
       "15795        1\n",
       "\n",
       "[23800 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's test the new function:\n",
    "\n",
    "# Send the new dataframe to the function we created\n",
    "new_col(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify numerical and categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            int64\n",
       "Medu           int64\n",
       "Fedu           int64\n",
       "traveltime     int64\n",
       "studytime      int64\n",
       "failures       int64\n",
       "famrel         int64\n",
       "freetime       int64\n",
       "goout          int64\n",
       "health         int64\n",
       "absences       int64\n",
       "gender        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = train_inputs.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns = train_inputs.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the binary columns so we can pass them through without transforming\n",
    "#binary_columns = ['host_is_superhost', 'host_identity_verified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'traveltime',\n",
       " 'studytime',\n",
       " 'failures',\n",
       " 'famrel',\n",
       " 'freetime',\n",
       " 'goout',\n",
       " 'health',\n",
       " 'absences']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_columns = ['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_column = Pipeline(steps=[('my_new_column', FunctionTransformer(new_col)),\n",
    "                               ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        #('binary', binary_transformer, binary_columns),\n",
    "        ('trans', my_new_column, transformed_columns)],\n",
    "        remainder='passthrough')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform: fit_transform() for TRAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66643886,  0.96597412,  0.90362635, ...,  1.        ,\n",
       "         0.        , -0.36853945],\n",
       "       [ 0.66643886, -0.93881619, -1.68666277, ...,  0.        ,\n",
       "         1.        , -0.36853945],\n",
       "       [ 0.66643886,  0.33104402,  0.04019664, ...,  0.        ,\n",
       "         1.        , -0.36853945],\n",
       "       ...,\n",
       "       [ 0.66643886, -2.20867639, -2.55009248, ...,  1.        ,\n",
       "         0.        , -0.36853945],\n",
       "       [ 1.6195814 , -0.30388608, -1.68666277, ...,  0.        ,\n",
       "         1.        ,  2.71341375],\n",
       "       [ 1.6195814 , -0.30388608, -2.55009248, ...,  0.        ,\n",
       "         1.        ,  2.71341375]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit and transform the train data\n",
    "train_x = preprocessor.fit_transform(train_inputs)\n",
    "\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23800, 14)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tranform: transform() for TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.23984621,  0.33104402,  1.76705606, ...,  1.        ,\n",
       "         0.        , -0.36853945],\n",
       "       [-1.23984621, -0.30388608,  0.04019664, ...,  0.        ,\n",
       "         1.        , -0.36853945],\n",
       "       [-0.28670367,  0.33104402,  0.04019664, ...,  0.        ,\n",
       "         1.        , -0.36853945],\n",
       "       ...,\n",
       "       [ 0.66643886, -0.30388608,  0.04019664, ...,  1.        ,\n",
       "         0.        , -0.36853945],\n",
       "       [-1.23984621, -0.93881619,  0.04019664, ...,  0.        ,\n",
       "         1.        , -0.36853945],\n",
       "       [-1.23984621,  0.96597412,  0.04019664, ...,  1.        ,\n",
       "         0.        , -0.36853945]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "test_x = preprocessor.transform(test_inputs)\n",
    "\n",
    "test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10200, 14)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.523487\n",
       "1    0.476513\n",
       "Name: alc, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.value_counts()/len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard voting classifier (should include at least two models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(max_depth=10)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=15, max_iter=1000,\n",
       "                                                 multi_class='multinomial')),\n",
       "                             ('sgd', SGDClassifier(max_iter=10000))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "\n",
    "dtree_clf = DecisionTreeClassifier(max_depth=10)\n",
    "log_clf = LogisticRegression(multi_class='multinomial',solver = 'lbfgs', C=15, max_iter=1000)\n",
    "#log_clf = LogisticRegression(multi_class='multinomial',solver = 'saga', C=12, max_iter=1000)\n",
    "sgd_clf = SGDClassifier(max_iter=10000, tol=1e-3)\n",
    "#sgd_clf2 = SGDClassifier(max_iter=10000, tol=1e-3,penalty='elasticnet')\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf), \n",
    "                        ('sgd', sgd_clf),\n",
    "                       #('sgd2',sgd_clf2)\n",
    "                       ],\n",
    "            voting='hard')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.826764705882353\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8216666666666667\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4380,  918],\n",
       "       [ 901, 4001]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect each classifier's accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Test acc= 0.7995098039215687\n",
      "LogisticRegression Test acc= 0.8213725490196079\n",
      "SGDClassifier Test acc= 0.8116666666666666\n",
      "VotingClassifier Test acc= 0.8208823529411765\n"
     ]
    }
   ],
   "source": [
    "for clf in (dtree_clf, log_clf, sgd_clf, voting_clf):\n",
    "    clf.fit(train_x, train_y.ravel())\n",
    "    test_y_pred = clf.predict(test_x)\n",
    "    print(clf.__class__.__name__, 'Test acc=', accuracy_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard voting Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(max_depth=10)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=8, max_iter=1000,\n",
       "                                                 multi_class='multinomial')),\n",
       "                             ('sgd', SGDClassifier(max_iter=10000)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1, coef0=1, degree=2, kernel='poly'))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "dtree_clf = DecisionTreeClassifier(max_depth=10)\n",
    "log_clf = LogisticRegression(multi_class='multinomial',solver = 'lbfgs', C=8, max_iter=1000)\n",
    "sgd_clf = SGDClassifier(max_iter=10000, tol=1e-3)\n",
    "svc_clf=SVC(kernel=\"poly\", degree=2, coef0=1, C=1, gamma='scale')\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf), \n",
    "                        ('sgd', sgd_clf),\n",
    "                       ('svc',svc_clf)],\n",
    "            voting='hard')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8294117647058824\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8237254901960784\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4563,  735],\n",
       "       [1063, 3839]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect each classifier's accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier Test acc= 0.7994117647058824\n",
      "LogisticRegression Test acc= 0.8213725490196079\n",
      "SGDClassifier Test acc= 0.8198039215686275\n",
      "SVC Test acc= 0.8338235294117647\n",
      "VotingClassifier Test acc= 0.826764705882353\n"
     ]
    }
   ],
   "source": [
    "for clf in (dtree_clf, log_clf, sgd_clf, svc_clf,voting_clf):\n",
    "    clf.fit(train_x, train_y.ravel())\n",
    "    test_y_pred = clf.predict(test_x)\n",
    "    print(clf.__class__.__name__, 'Test acc=', accuracy_score(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft voting classifier (should include at least two models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft voting Classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(max_depth=10)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=8, max_iter=1000,\n",
       "                                                 multi_class='multinomial'))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each model should have predict_proba() function. Otherwise, you can't use it for soft voting\n",
    "#We can't use sgd, because it doesn't have predict_proba() function.\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf)],\n",
    "            voting='soft')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8438235294117648\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8156862745098039\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Voting Classifier 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt', DecisionTreeClassifier(max_depth=10)),\n",
       "                             ('lr',\n",
       "                              LogisticRegression(C=8, max_iter=1000,\n",
       "                                                 multi_class='multinomial')),\n",
       "                             ('rnd',\n",
       "                              RandomForestClassifier(n_estimators=600,\n",
       "                                                     n_jobs=-1))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Each model should have predict_proba() function. Otherwise, you can't use it for soft voting\n",
    "#We can't use sgd, because it doesn't have predict_proba() function.\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rnd_clf = RandomForestClassifier(n_estimators=600, n_jobs=-1)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "            estimators=[('dt', dtree_clf), \n",
    "                        ('lr', log_clf),\n",
    "                         ('rnd',rnd_clf)\n",
    "                       ],\n",
    "            voting='soft')\n",
    "\n",
    "voting_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9039915966386555\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = voting_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.818921568627451\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = voting_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=SVC(C=1, coef0=1, degree=2, kernel='poly'),\n",
       "                  max_samples=1000, n_estimators=50, n_jobs=-1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier \n",
    "\n",
    "\n",
    "#If you want to do pasting, change \"bootstrap=False\"\n",
    "#n_jobs=-1 means use all CPU cores\n",
    "#bagging automatically performs soft voting\n",
    "\n",
    "#bag_clf = BaggingClassifier( \n",
    "#            SGDClassifier(), n_estimators=50, \n",
    "#            max_samples=1000, bootstrap=True, n_jobs=-1) \n",
    "\n",
    "#svc_clf=BaggingClassifier(\n",
    "#        SVC(kernel=\"linear\"),n_estimators=50, \n",
    "#           max_samples=1000, bootstrap=True, n_jobs=-1)\n",
    "\n",
    "bag_clf =BaggingClassifier(SVC(kernel=\"poly\", degree=2, coef0=1, C=1, gamma='scale'),n_estimators=50, \n",
    "           max_samples=1000, bootstrap=True, n_jobs=-1) #-->83%\n",
    "#svc_clf =BaggingClassifier(SVC(kernel=\"rbf\"),n_estimators=50, \n",
    "#          max_samples=1000, bootstrap=True, n_jobs=-1) -->82.6%\n",
    "\n",
    "bag_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8320588235294117\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = bag_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8306862745098039\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = bag_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc)) ##Best model so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000, n_jobs=-1) #500 98% & 80.5%\n",
    "\n",
    "rnd_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9829831932773109\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = rnd_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8054901960784314\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = rnd_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   learning_rate=0.1, n_estimators=500)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "\n",
    "#Create Adapative Boosting with Decision Stumps (depth=1) ##intial depth 1, test accuracy 82%\n",
    "ada_clf = AdaBoostClassifier( \n",
    "            DecisionTreeClassifier(max_depth=1), n_estimators=500, \n",
    "            algorithm=\"SAMME.R\", learning_rate=0.1) \n",
    "\n",
    "ada_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8209243697478992\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = ada_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8195098039215686\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = ada_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=8)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use GradientBoosting-was not in assignment\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier#use depth 2,8,10\n",
    "\n",
    "gbclf = GradientBoostingClassifier(max_depth=8, n_estimators=100, learning_rate=0.1) \n",
    "\n",
    "gbclf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8914285714285715\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = gbclf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.823921568627451\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = gbclf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=10, subsample=0.75)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train on 75% of the sample only\n",
    "from sklearn.ensemble import GradientBoostingClassifier #check with depth 2\n",
    "\n",
    "gbclf = GradientBoostingClassifier(max_depth=10, n_estimators=100, \n",
    "                                   learning_rate=0.1, subsample=0.75) \n",
    "\n",
    "gbclf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.944201680672269\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = gbclf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8140196078431372\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = gbclf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Estimators = 1     Train accuracy = 0.8171   Test accuracy = 0.7993\n",
      "# Estimators = 2     Train accuracy = 0.8337   Test accuracy = 0.809\n",
      "# Estimators = 3     Train accuracy = 0.8411   Test accuracy = 0.8102\n",
      "# Estimators = 4     Train accuracy = 0.8474   Test accuracy = 0.8155\n",
      "# Estimators = 5     Train accuracy = 0.8514   Test accuracy = 0.8126\n",
      "# Estimators = 6     Train accuracy = 0.857   Test accuracy = 0.8138\n",
      "# Estimators = 7     Train accuracy = 0.8632   Test accuracy = 0.8111\n",
      "# Estimators = 8     Train accuracy = 0.8668   Test accuracy = 0.8108\n",
      "# Estimators = 9     Train accuracy = 0.8683   Test accuracy = 0.8114\n",
      "# Estimators = 10     Train accuracy = 0.8708   Test accuracy = 0.8095\n",
      "# Estimators = 11     Train accuracy = 0.8746   Test accuracy = 0.8061\n",
      "# Estimators = 12     Train accuracy = 0.8767   Test accuracy = 0.8055\n",
      "# Estimators = 13     Train accuracy = 0.8782   Test accuracy = 0.8091\n",
      "# Estimators = 14     Train accuracy = 0.884   Test accuracy = 0.8018\n",
      "# Estimators = 15     Train accuracy = 0.8858   Test accuracy = 0.8069\n",
      "# Estimators = 16     Train accuracy = 0.8894   Test accuracy = 0.804\n",
      "# Estimators = 17     Train accuracy = 0.8961   Test accuracy = 0.8035\n",
      "# Estimators = 18     Train accuracy = 0.8951   Test accuracy = 0.8026\n",
      "# Estimators = 19     Train accuracy = 0.9013   Test accuracy = 0.8011\n",
      "# Estimators = 20     Train accuracy = 0.8951   Test accuracy = 0.8045\n",
      "# Estimators = 21     Train accuracy = 0.9024   Test accuracy = 0.8019\n",
      "# Estimators = 22     Train accuracy = 0.9066   Test accuracy = 0.8004\n",
      "# Estimators = 23     Train accuracy = 0.9052   Test accuracy = 0.8025\n",
      "# Estimators = 24     Train accuracy = 0.9101   Test accuracy = 0.8007\n",
      "# Estimators = 25     Train accuracy = 0.9121   Test accuracy = 0.7987\n",
      "# Estimators = 26     Train accuracy = 0.9121   Test accuracy = 0.7967\n",
      "# Estimators = 27     Train accuracy = 0.9176   Test accuracy = 0.7939\n",
      "# Estimators = 28     Train accuracy = 0.9175   Test accuracy = 0.7984\n",
      "# Estimators = 29     Train accuracy = 0.9152   Test accuracy = 0.7999\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,30):\n",
    "    gbclf = GradientBoostingClassifier(max_depth=8, n_estimators=x, learning_rate=1.0) \n",
    "    gbclf.fit(train_x, train_y.ravel())\n",
    "    \n",
    "    train_predictions = gbclf.predict(train_x)\n",
    "    test_predictions = gbclf.predict(test_x)\n",
    "    \n",
    "    train_accuracy = round(accuracy_score(train_y, train_predictions),4)\n",
    "    test_accuracy = round(accuracy_score(test_y, test_predictions),4)\n",
    "    \n",
    "    print('# Estimators = {}'.format(x) + \"     \" + 'Train accuracy = {}'.format(train_accuracy) + \"   \"\n",
    "         'Test accuracy = {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#none of the estimators beat best model (bagging classifier) test accuracy of 83%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anush\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:42:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost\n",
    "xgb_clf = xgboost.XGBClassifier()\n",
    "\n",
    "xgb_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.867436974789916\n"
     ]
    }
   ],
   "source": [
    "#Train accuracy\n",
    "\n",
    "train_y_pred = xgb_clf.predict(train_x)\n",
    "\n",
    "train_acc = accuracy_score(train_y, train_y_pred)\n",
    "\n",
    "print('Train acc: {}' .format(train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8266666666666667\n"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "\n",
    "test_y_pred = xgb_clf.predict(test_x)\n",
    "\n",
    "test_acc = accuracy_score(test_y, test_y_pred)\n",
    "\n",
    "print('Test acc: {}' .format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above model is still not the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Briefly answer the following questions: (2 points) \n",
    "1) Which model performs the best (and why)?<br>\n",
    "2) What is the baseline?<br>\n",
    "3) Does the best model perform better than the baseline (and why)?<br>\n",
    "4) Does the best model exhibit any overfitting; what did you do about it?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) The bagging classifier performs best with test accuracy of 83.1% higher than other model test accuracies.\n",
    "2) The baseline accuracy is 52.3%\n",
    "3) The best model performs better than baseline(83.1% test accuracy is greater than 52.3%).\n",
    "4) The best model does not exhibit any overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_competition = pd.read_csv(\"alcohol_competition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "alcohol_competition=alcohol_competition.drop(['ID'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsAdult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     IsAdult\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          1\n",
       "4          0\n",
       "..       ...\n",
       "995        0\n",
       "996        0\n",
       "997        1\n",
       "998        0\n",
       "999        1\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df = alcohol_competition[['age']]\n",
    "\n",
    "# Send the new dataframe to the function we created\n",
    "new_col(subset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            int64\n",
       "Medu           int64\n",
       "Fedu           int64\n",
       "traveltime     int64\n",
       "studytime      int64\n",
       "failures       int64\n",
       "famrel         int64\n",
       "freetime       int64\n",
       "goout          int64\n",
       "health         int64\n",
       "absences       int64\n",
       "gender        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alcohol_competition.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.66643886,  0.33104402,  0.04019664, ...,  1.        ,\n",
       "         0.        , -0.36853945],\n",
       "       [-1.23984621,  2.23583433,  2.63048577, ...,  1.        ,\n",
       "         0.        , -0.36853945],\n",
       "       [ 0.66643886,  0.33104402,  0.04019664, ...,  1.        ,\n",
       "         0.        , -0.36853945],\n",
       "       ...,\n",
       "       [ 1.6195814 ,  0.33104402, -0.82323307, ...,  0.        ,\n",
       "         1.        ,  2.71341375],\n",
       "       [ 0.66643886, -0.30388608,  0.04019664, ...,  0.        ,\n",
       "         1.        , -0.36853945],\n",
       "       [ 1.6195814 ,  0.33104402, -0.82323307, ...,  1.        ,\n",
       "         0.        ,  2.71341375]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the test data\n",
    "testalcohol = preprocessor.transform(alcohol_competition)\n",
    "\n",
    "testalcohol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestprediction = bag_clf.predict(testalcohol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestpredictiondf=pd.DataFrame(bestprediction,columns=['Alc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestpredictiondf.insert(1, \"ID\", np.arange(1, 1001, 1).tolist(), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alc</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alc  ID\n",
       "0    0   1\n",
       "1    0   2\n",
       "2    1   3\n",
       "3    1   4\n",
       "4    0   5"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestpredictiondf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestpredictiondf.to_csv('salian_tm_competition.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
