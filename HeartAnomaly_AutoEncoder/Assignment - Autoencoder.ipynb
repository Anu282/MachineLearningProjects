{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment - Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set contains data about patients with and without heart problems. Each row represents a single patient. There two files: heart-normal (contains patients without any heart problems) and heart_anomaly (contains patients with heart problems). This is an anomaly detection task: build an autoencoder on normal patients to identify anomalous observations. You cannot do supervised learning, because there are only 20 anomalous observations - which is not enough to build a binary classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "The description of variables are provided in \"Heart - Data Dictionary.docx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **heart-normal.csv** data set to train an autoencoder on healthy (i.e., normal) patients. Then, use the observations in **heart-anomaly.csv** data set to check whether the autoencoder can successfully detect patients who have a heart anomaly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartnormal = pd.read_csv(\"heart-normal.csv\")\n",
    "heartnormal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>268</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   67    1   0       160   286    0        0      108      1      1.5      1   \n",
       "1   67    1   0       120   229    0        0      129      1      2.6      1   \n",
       "2   62    0   0       140   268    0        0      160      0      3.6      0   \n",
       "3   63    1   0       130   254    0        0      147      0      1.4      1   \n",
       "4   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "\n",
       "   ca  thal  \n",
       "0   3     2  \n",
       "1   2     3  \n",
       "2   2     2  \n",
       "3   1     3  \n",
       "4   0     3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartanomaly=pd.read_csv(\"heart-anomaly.csv\")\n",
    "heartanomaly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartnormal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heartanomaly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the numerical columns\n",
    "numeric_columns = heartnormal.select_dtypes(include=[np.number]).columns.to_list()\n",
    "\n",
    "# Identify the categorical columns\n",
    "categorical_columns =['thal'] ##heartnormal.select_dtypes('object').columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_columns = ['sex', 'fbs','exang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary_columns:\n",
    "    numeric_columns.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'fbs', 'exang']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'cp',\n",
       " 'trestbps',\n",
       " 'chol',\n",
       " 'restecg',\n",
       " 'thalach',\n",
       " 'oldpeak',\n",
       " 'slope',\n",
       " 'ca',\n",
       " 'thal']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thal']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns),\n",
    "        ('binary', binary_transformer, binary_columns)],\n",
    "        remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.10306652,  1.71093264,  0.97372481, ...,  1.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [-1.62754823,  0.65755993,  0.04323489, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.20745366, -0.39581278,  0.04323489, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-1.20745366, -0.39581278, -0.57709173, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.52252459,  0.65755993,  0.53949618, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.52252459,  0.65755993,  0.53949618, ...,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_x = preprocessor.fit_transform(heartnormal)\n",
    "\n",
    "normal_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 17)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5231611 , -1.44918549,  1.90421473,  0.81980549, -1.18012347,\n",
       "        -2.6400108 ,  1.17814884, -1.0035591 ,  3.1150997 , -0.26104233,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.5231611 , -1.44918549, -0.57709173, -0.24780329, -1.18012347,\n",
       "        -1.54145941,  2.59146023, -1.0035591 ,  1.93351016,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.99804287, -1.44918549,  0.6635615 ,  0.48266588, -1.18012347,\n",
       "         0.08021169,  3.87628877, -2.69322494,  1.93351016, -0.26104233,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.10306652, -1.44918549,  0.04323489,  0.22044617, -1.18012347,\n",
       "        -0.59984393,  1.04966598, -1.0035591 ,  0.75192062,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.05283008, -1.44918549,  0.6635615 , -0.73478274, -1.18012347,\n",
       "        -0.18134817,  3.2338745 , -2.69322494, -0.42966892,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.36790101,  0.65755993,  0.04323489,  0.25790613, -1.18012347,\n",
       "        -0.86140379,  0.02180315, -1.0035591 ,  0.75192062, -2.4146416 ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [-0.47228815, -0.39581278, -1.19741835, -0.24780329,  0.80681911,\n",
       "         0.49870746,  0.53573457, -2.69322494, -0.42966892,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.5779483 , -0.39581278, -0.57709173,  0.78234554, -1.18012347,\n",
       "         0.08021169,  1.5635974 , -1.0035591 , -0.42966892, -0.26104233,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.5779483 ,  0.65755993,  0.16730021, -0.34145319, -1.18012347,\n",
       "         0.76026731,  3.36235735,  0.68610673,  1.93351016,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.78799559, -1.44918549,  0.04323489, -0.67859281, -1.18012347,\n",
       "        -1.38452349,  2.33449452, -1.0035591 ,  1.93351016,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-1.3124773 , -1.44918549, -1.19741835, -1.40906198, -1.18012347,\n",
       "        -2.32613897,  1.8205631 , -1.0035591 , -0.42966892,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.78799559, -1.44918549, -0.76318971, -0.22907332,  0.80681911,\n",
       "         0.08021169,  1.04966598,  0.68610673,  1.93351016,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.20809016,  0.65755993,  0.6635615 ,  1.73757445,  0.80681911,\n",
       "        -0.02441225, -0.74909397,  0.68610673, -0.42966892, -0.26104233,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.99740637, -1.44918549, -0.57709173, -1.22176219, -1.18012347,\n",
       "        -2.01226714,  2.46297737, -1.0035591 , -0.42966892,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.47292465, -1.44918549,  1.28388812,  0.63250571, -1.18012347,\n",
       "        -2.43076291,  0.02180315, -1.0035591 ,  0.75192062, -2.4146416 ,\n",
       "         0.        ,  1.        ,  0.        ,  0.        ,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 0.26287736, -1.44918549,  0.16730021,  2.07471407,  0.80681911,\n",
       "        -1.38452349,  0.79270027, -1.0035591 ,  0.75192062,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [ 1.31311381, -1.44918549,  1.28388812, -0.32272321, -1.18012347,\n",
       "        -2.32613897,  0.53573457, -1.0035591 ,  3.1150997 ,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.89301923, -1.44918549,  0.04323489,  1.64392456, -1.18012347,\n",
       "         0.55101943, -0.74909397,  0.68610673, -0.42966892, -0.26104233,\n",
       "         0.        ,  0.        ,  1.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.5779483 ,  0.65755993, -1.07335302, -0.22907332, -1.18012347,\n",
       "         0.34177154,  2.46297737, -1.0035591 ,  0.75192062,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.26224086, -1.44918549,  1.28388812,  0.01441641, -1.18012347,\n",
       "        -1.59377138,  2.59146023, -1.0035591 , -0.42966892,  1.89255693,\n",
       "         0.        ,  0.        ,  0.        ,  1.        ,  1.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_x = preprocessor.transform(heartanomaly)\n",
    "\n",
    "anomaly_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 17)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                900       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                867       \n",
      "=================================================================\n",
      "Total params: 4,317\n",
      "Trainable params: 4,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "#Encoder\n",
    "model.add(keras.layers.InputLayer(input_shape=17))\n",
    "model.add(keras.layers.Dense(50, activation='selu'))\n",
    "#model.add(keras.layers.Dense(50, activation='selu'))\n",
    "\n",
    "#Decoder\n",
    "model.add(keras.layers.Dense(50, activation='selu'))\n",
    "model.add(keras.layers.Dense(17))  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 242ms/step - loss: 1.2597 - mean_squared_error: 1.2597 - val_loss: 1.1279 - val_mean_squared_error: 1.1279\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 1.0992 - mean_squared_error: 1.0992 - val_loss: 0.9844 - val_mean_squared_error: 0.9844\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.9592 - mean_squared_error: 0.9592 - val_loss: 0.8578 - val_mean_squared_error: 0.8578\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.8398 - mean_squared_error: 0.8398 - val_loss: 0.7469 - val_mean_squared_error: 0.7469\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7288 - mean_squared_error: 0.7288 - val_loss: 0.6509 - val_mean_squared_error: 0.6509\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6337 - mean_squared_error: 0.6337 - val_loss: 0.5676 - val_mean_squared_error: 0.5676\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5548 - mean_squared_error: 0.5548 - val_loss: 0.4951 - val_mean_squared_error: 0.4951\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4813 - mean_squared_error: 0.4813 - val_loss: 0.4327 - val_mean_squared_error: 0.4327\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4220 - mean_squared_error: 0.4220 - val_loss: 0.3787 - val_mean_squared_error: 0.3787\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3683 - mean_squared_error: 0.3683 - val_loss: 0.3324 - val_mean_squared_error: 0.3324\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3243 - mean_squared_error: 0.3243 - val_loss: 0.2926 - val_mean_squared_error: 0.2926\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2856 - mean_squared_error: 0.2856 - val_loss: 0.2586 - val_mean_squared_error: 0.2586\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2523 - mean_squared_error: 0.2523 - val_loss: 0.2296 - val_mean_squared_error: 0.2296\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2243 - mean_squared_error: 0.2243 - val_loss: 0.2048 - val_mean_squared_error: 0.2048\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2005 - mean_squared_error: 0.2005 - val_loss: 0.1835 - val_mean_squared_error: 0.1835\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1796 - mean_squared_error: 0.1796 - val_loss: 0.1655 - val_mean_squared_error: 0.1655\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1623 - mean_squared_error: 0.1623 - val_loss: 0.1499 - val_mean_squared_error: 0.1499\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.1472 - mean_squared_error: 0.1472 - val_loss: 0.1365 - val_mean_squared_error: 0.1365\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1344 - mean_squared_error: 0.1344 - val_loss: 0.1249 - val_mean_squared_error: 0.1249\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1230 - mean_squared_error: 0.1230 - val_loss: 0.1149 - val_mean_squared_error: 0.1149\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1129 - mean_squared_error: 0.1129 - val_loss: 0.1061 - val_mean_squared_error: 0.1061\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1045 - mean_squared_error: 0.1045 - val_loss: 0.0983 - val_mean_squared_error: 0.0983\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0968 - mean_squared_error: 0.0968 - val_loss: 0.0914 - val_mean_squared_error: 0.0914\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0902 - mean_squared_error: 0.0902 - val_loss: 0.0852 - val_mean_squared_error: 0.0852\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0842 - mean_squared_error: 0.0842 - val_loss: 0.0797 - val_mean_squared_error: 0.0797\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0788 - mean_squared_error: 0.0788 - val_loss: 0.0748 - val_mean_squared_error: 0.0748\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0739 - mean_squared_error: 0.0739 - val_loss: 0.0703 - val_mean_squared_error: 0.0703\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0696 - mean_squared_error: 0.0696 - val_loss: 0.0662 - val_mean_squared_error: 0.0662\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0656 - mean_squared_error: 0.0656 - val_loss: 0.0626 - val_mean_squared_error: 0.0626\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0618 - mean_squared_error: 0.0618 - val_loss: 0.0592 - val_mean_squared_error: 0.0592\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0586 - mean_squared_error: 0.0586 - val_loss: 0.0561 - val_mean_squared_error: 0.0561\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0556 - mean_squared_error: 0.0556 - val_loss: 0.0533 - val_mean_squared_error: 0.0533\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0528 - mean_squared_error: 0.0528 - val_loss: 0.0507 - val_mean_squared_error: 0.0507\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0503 - mean_squared_error: 0.0503 - val_loss: 0.0483 - val_mean_squared_error: 0.0483\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0479 - mean_squared_error: 0.0479 - val_loss: 0.0461 - val_mean_squared_error: 0.0461\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0458 - mean_squared_error: 0.0458 - val_loss: 0.0441 - val_mean_squared_error: 0.0441\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0438 - mean_squared_error: 0.0438 - val_loss: 0.0423 - val_mean_squared_error: 0.0423\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0420 - mean_squared_error: 0.0420 - val_loss: 0.0405 - val_mean_squared_error: 0.0405\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0403 - mean_squared_error: 0.0403 - val_loss: 0.0389 - val_mean_squared_error: 0.0389\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0386 - mean_squared_error: 0.0386 - val_loss: 0.0374 - val_mean_squared_error: 0.0374\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0360 - val_mean_squared_error: 0.0360\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0347 - val_mean_squared_error: 0.0347\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0345 - mean_squared_error: 0.0345 - val_loss: 0.0335 - val_mean_squared_error: 0.0335\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0324 - val_mean_squared_error: 0.0324\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0322 - mean_squared_error: 0.0322 - val_loss: 0.0313 - val_mean_squared_error: 0.0313\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0311 - mean_squared_error: 0.0311 - val_loss: 0.0303 - val_mean_squared_error: 0.0303\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0301 - mean_squared_error: 0.0301 - val_loss: 0.0294 - val_mean_squared_error: 0.0294\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0292 - mean_squared_error: 0.0292 - val_loss: 0.0285 - val_mean_squared_error: 0.0285\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0284 - mean_squared_error: 0.0284 - val_loss: 0.0277 - val_mean_squared_error: 0.0277\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.0269 - val_mean_squared_error: 0.0269\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0262 - val_mean_squared_error: 0.0262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0260 - mean_squared_error: 0.0260 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0248 - val_mean_squared_error: 0.0248\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0241 - mean_squared_error: 0.0241 - val_loss: 0.0236 - val_mean_squared_error: 0.0236\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0220 - val_mean_squared_error: 0.0220\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0215 - val_mean_squared_error: 0.0215\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0210 - val_mean_squared_error: 0.0210\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0210 - mean_squared_error: 0.0210 - val_loss: 0.0206 - val_mean_squared_error: 0.0206\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0205 - mean_squared_error: 0.0205 - val_loss: 0.0202 - val_mean_squared_error: 0.0202\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0201 - mean_squared_error: 0.0201 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0197 - mean_squared_error: 0.0197 - val_loss: 0.0194 - val_mean_squared_error: 0.0194\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0190 - val_mean_squared_error: 0.0190\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0190 - mean_squared_error: 0.0190 - val_loss: 0.0186 - val_mean_squared_error: 0.0186\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0186 - mean_squared_error: 0.0186 - val_loss: 0.0183 - val_mean_squared_error: 0.0183\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0179 - mean_squared_error: 0.0179 - val_loss: 0.0177 - val_mean_squared_error: 0.0177\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0177 - mean_squared_error: 0.0177 - val_loss: 0.0174 - val_mean_squared_error: 0.0174\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0173 - mean_squared_error: 0.0173 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0168 - val_mean_squared_error: 0.0168\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0166 - val_mean_squared_error: 0.0166\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0165 - mean_squared_error: 0.0165 - val_loss: 0.0163 - val_mean_squared_error: 0.0163\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0163 - mean_squared_error: 0.0163 - val_loss: 0.0160 - val_mean_squared_error: 0.0160\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0160 - mean_squared_error: 0.0160 - val_loss: 0.0158 - val_mean_squared_error: 0.0158\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0153 - val_mean_squared_error: 0.0153\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0153 - mean_squared_error: 0.0153 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0151 - mean_squared_error: 0.0151 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0147 - mean_squared_error: 0.0147 - val_loss: 0.0145 - val_mean_squared_error: 0.0145\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0143 - val_mean_squared_error: 0.0143\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0141 - val_mean_squared_error: 0.0141\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0138 - val_mean_squared_error: 0.0138\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0138 - mean_squared_error: 0.0138 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0133 - val_mean_squared_error: 0.0133\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0131 - val_mean_squared_error: 0.0131\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0124 - val_mean_squared_error: 0.0124\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0121 - val_mean_squared_error: 0.0121\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0121 - mean_squared_error: 0.0121 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0115 - mean_squared_error: 0.0115 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0112 - mean_squared_error: 0.0112 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0111 - mean_squared_error: 0.0111 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0108 - mean_squared_error: 0.0108 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0104 - mean_squared_error: 0.0104 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0095 - val_mean_squared_error: 0.0095\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0091 - val_mean_squared_error: 0.0091\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0089 - val_mean_squared_error: 0.0089\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0087 - val_mean_squared_error: 0.0087\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0085 - val_mean_squared_error: 0.0085\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0084 - mean_squared_error: 0.0084 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0082 - val_mean_squared_error: 0.0082\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0071 - val_mean_squared_error: 0.0071\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0068 - val_mean_squared_error: 0.0068\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0067 - val_mean_squared_error: 0.0067\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0064 - val_mean_squared_error: 0.0064\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0063 - val_mean_squared_error: 0.0063\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0061 - val_mean_squared_error: 0.0061\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0060 - val_mean_squared_error: 0.0060\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0059 - val_mean_squared_error: 0.0059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5049f3bb0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Be careful: both input and output are \"housing_normal_std\" while training the autoencoder\n",
    "\n",
    "model.fit(normal_x, normal_x, \n",
    "          validation_data = (normal_x, normal_x),\n",
    "          epochs=200, batch_size=100, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 997us/step - loss: 0.0059 - mean_squared_error: 0.0059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.005915837828069925, 0.005915837828069925]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(normal_x, normal_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 793us/step - loss: 0.0059 - mean_squared_error: 0.0059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.915837828069925"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(normal_x, normal_x)[0]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.024617154151201248, 0.024617154151201248]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(anomaly_x, anomaly_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0246 - mean_squared_error: 0.0246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.617154151201248"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(anomaly_x, anomaly_x)[0]*1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict first 20 in normal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.6382604640009\n",
      "9.243500150138903\n",
      "4.312235488242118\n",
      "6.5294653732704475\n",
      "5.4464361843314135\n",
      "4.527891619218368\n",
      "3.822508051588053\n",
      "5.166946745002025\n",
      "3.909497641122364\n",
      "3.9008178473206794\n",
      "3.6703807555471024\n",
      "3.4455560279152486\n",
      "7.2481507542067005\n",
      "3.2690632714584322\n",
      "6.423045023348083\n",
      "5.021313112857455\n",
      "11.8869246417369\n",
      "7.187158887288646\n",
      "7.901355638665102\n",
      "3.2184421284794325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error##error generated for each airbnb listing\n",
    "\n",
    "for i in range(1,21):\n",
    "    prediction = model.predict(normal_x[i:i+1])\n",
    "    print((mean_squared_error(normal_x[i:i+1], prediction))*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict all 20 in anomaly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.22687665272411\n",
      "42.44947338210777\n",
      "10.053766237262685\n",
      "47.60404443244025\n",
      "11.026728487264728\n",
      "16.550880693859014\n",
      "8.915174605055528\n",
      "76.304948939606\n",
      "23.949957713799634\n",
      "23.135347947583895\n",
      "23.076534088020885\n",
      "6.463911978903473\n",
      "20.33274454865855\n",
      "13.700030530189997\n",
      "4.864474453199608\n",
      "49.363163205934114\n",
      "9.368561361093434\n",
      "13.052660530077793\n",
      "11.02258235342397\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    prediction = model.predict(anomaly_x[i:i+1])\n",
    "    print((mean_squared_error(anomaly_x[i:i+1], prediction))*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Provide a brief discussion (one-paragraph): can the model successfully detect patients with heart anomalies? If not, why? <br>\n",
    "Discuss any other relevant issues about your autoencoder. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model does detect patients with heart anomalies but sometimes misclassifies the normal people as those with heart anomalies.\n",
    "From the prediction for anomaly data, error rates for some of the observations were 8.9,6.4,4.8,9.3 for these the error rate is similar to normal data and hence misclassified.Also for normal data the first prediction of 23.6 is misclassified as normal where its error rate is similar to that of anomaly data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Credit (3 points):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GAN\n",
    "\n",
    "Build a GAN that can generate patients with **normal hearts**. Test the effectiveness of your GAN using the autoencoder you built earlier. Hint: when you send your newly generated data to the autoencoder, the error term should be small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "codings_size = 100   # this is the number of input variables we want the generator to use\n",
    "\n",
    "generator = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=codings_size),\n",
    "    keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dense(40, activation=\"relu\"),\n",
    "    keras.layers.Dense(17, activation=None)    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 40)                4040      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 40)                1640      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 17)                697       \n",
      "=================================================================\n",
      "Total params: 6,377\n",
      "Trainable params: 6,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=[17]),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(25, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 50)                900       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 26        \n",
      "=================================================================\n",
      "Total params: 2,201\n",
      "Trainable params: 2,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = keras.models.Sequential([generator, discriminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "discriminator.trainable = False\n",
    "gan.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices(normal_x).shuffle(1000)\n",
    "\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan, dataset, batch_size, codings_size, n_epochs=10):\n",
    "    generator, discriminator = gan.layers\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch in dataset:\n",
    "            # phase 1 - training the discriminator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            generated_data = tf.cast(generator(noise), tf.float64)\n",
    "            X_fake_and_real = tf.concat([generated_data, X_batch], axis=0)\n",
    "            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
    "            discriminator.trainable = True\n",
    "            discriminator.train_on_batch(X_fake_and_real, y1)\n",
    "            # phase 2 - training the generator\n",
    "            noise = tf.random.normal(shape=[batch_size, codings_size])\n",
    "            y2 = tf.constant([[1.]] * batch_size)\n",
    "            discriminator.trainable = False\n",
    "            gan.train_on_batch(noise, y2)\n",
    "        print(\"Epoch: {}/{}\".format(epoch, n_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100\n",
      "Epoch: 1/100\n",
      "Epoch: 2/100\n",
      "Epoch: 3/100\n",
      "Epoch: 4/100\n",
      "Epoch: 5/100\n",
      "Epoch: 6/100\n",
      "Epoch: 7/100\n",
      "Epoch: 8/100\n",
      "Epoch: 9/100\n",
      "Epoch: 10/100\n",
      "Epoch: 11/100\n",
      "Epoch: 12/100\n",
      "Epoch: 13/100\n",
      "Epoch: 14/100\n",
      "Epoch: 15/100\n",
      "Epoch: 16/100\n",
      "Epoch: 17/100\n",
      "Epoch: 18/100\n",
      "Epoch: 19/100\n",
      "Epoch: 20/100\n",
      "Epoch: 21/100\n",
      "Epoch: 22/100\n",
      "Epoch: 23/100\n",
      "Epoch: 24/100\n",
      "Epoch: 25/100\n",
      "Epoch: 26/100\n",
      "Epoch: 27/100\n",
      "Epoch: 28/100\n",
      "Epoch: 29/100\n",
      "Epoch: 30/100\n",
      "Epoch: 31/100\n",
      "Epoch: 32/100\n",
      "Epoch: 33/100\n",
      "Epoch: 34/100\n",
      "Epoch: 35/100\n",
      "Epoch: 36/100\n",
      "Epoch: 37/100\n",
      "Epoch: 38/100\n",
      "Epoch: 39/100\n",
      "Epoch: 40/100\n",
      "Epoch: 41/100\n",
      "Epoch: 42/100\n",
      "Epoch: 43/100\n",
      "Epoch: 44/100\n",
      "Epoch: 45/100\n",
      "Epoch: 46/100\n",
      "Epoch: 47/100\n",
      "Epoch: 48/100\n",
      "Epoch: 49/100\n",
      "Epoch: 50/100\n",
      "Epoch: 51/100\n",
      "Epoch: 52/100\n",
      "Epoch: 53/100\n",
      "Epoch: 54/100\n",
      "Epoch: 55/100\n",
      "Epoch: 56/100\n",
      "Epoch: 57/100\n",
      "Epoch: 58/100\n",
      "Epoch: 59/100\n",
      "Epoch: 60/100\n",
      "Epoch: 61/100\n",
      "Epoch: 62/100\n",
      "Epoch: 63/100\n",
      "Epoch: 64/100\n",
      "Epoch: 65/100\n",
      "Epoch: 66/100\n",
      "Epoch: 67/100\n",
      "Epoch: 68/100\n",
      "Epoch: 69/100\n",
      "Epoch: 70/100\n",
      "Epoch: 71/100\n",
      "Epoch: 72/100\n",
      "Epoch: 73/100\n",
      "Epoch: 74/100\n",
      "Epoch: 75/100\n",
      "Epoch: 76/100\n",
      "Epoch: 77/100\n",
      "Epoch: 78/100\n",
      "Epoch: 79/100\n",
      "Epoch: 80/100\n",
      "Epoch: 81/100\n",
      "Epoch: 82/100\n",
      "Epoch: 83/100\n",
      "Epoch: 84/100\n",
      "Epoch: 85/100\n",
      "Epoch: 86/100\n",
      "Epoch: 87/100\n",
      "Epoch: 88/100\n",
      "Epoch: 89/100\n",
      "Epoch: 90/100\n",
      "Epoch: 91/100\n",
      "Epoch: 92/100\n",
      "Epoch: 93/100\n",
      "Epoch: 94/100\n",
      "Epoch: 95/100\n",
      "Epoch: 96/100\n",
      "Epoch: 97/100\n",
      "Epoch: 98/100\n",
      "Epoch: 99/100\n"
     ]
    }
   ],
   "source": [
    "train_gan(gan, dataset, batch_size, codings_size, n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal(shape=[1, codings_size])\n",
    "generated_data = tf.cast(generator(noise), tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 17), dtype=float64, numpy=\n",
       "array([[-0.73013985, -2.47334981, -1.43780434, -0.39002925, -0.7204473 ,\n",
       "        -0.11289843,  0.00578984,  0.64840305, -1.35245073,  0.60112172,\n",
       "        -0.38344851, -0.10997078,  0.86434484,  0.35212845, -0.00317993,\n",
       "        -1.09569454, -0.27936321]])>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model.predict(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.637046511481294\n"
     ]
    }
   ],
   "source": [
    "print((mean_squared_error(generated_data,prediction))*1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "Provide a brief discussion (one-paragraph): can the GAN generate patients with normal heart? If not, why? <br>\n",
    "Discuss any other relevant issues about your GAN. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GAN cannot generate patients with normal heart since mean square error for the generated_data is way higher than the mean square error of anomaly dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
